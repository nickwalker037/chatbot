{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import json\n",
    "import csvmapper\n",
    "\n",
    "import nltk\n",
    "from nltk.stem.lancaster import LancasterStemmer\n",
    "import numpy as np\n",
    "import random\n",
    "import json\n",
    "import objectpath\n",
    "\n",
    "stemmer = LancasterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "csvfile = open(r'C:\\Users\\nicholas\\Downloads\\chatbot_to_json-Sheet1.csv', 'r')\n",
    "jsonfile = open(r'C:\\Users\\nicholas\\Desktop\\Python\\Chatbot\\FAQ\\intents_new.json', 'w')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "fieldnames = (\"Context\", \"Utterance\",\"Tag\",\"Context_set\",\"Context_link\")\n",
    "reader = csv.DictReader( csvfile, fieldnames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "for row in reader:\n",
    "    json.dump(row, jsonfile)\n",
    "    jsonfile.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./intents_new.json') as json_data:\n",
    "    intents = json.load(json_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hi\n",
      "Hey\n",
      "How are you?\n",
      "Is anyone there?\n",
      "Hello\n",
      "Good day\n",
      "sup\n",
      "what's up\n",
      "what's up\n",
      "yo\n",
      "Good morning\n",
      "Good Day\n",
      "good afternoon\n",
      "good evening\n",
      "long time no see\n",
      "Greetings!\n",
      "Hi, how is it going?\n",
      "Hi, how is it going?\n",
      "Hello\n",
      "Hey\n",
      "How are you doing?\n",
      "How are you doing?\n",
      "Nice to meet you\n",
      "How do you do?\n",
      "Hi, nice to meet you\n",
      "Top of the morning to you!\n",
      "It is a pleasure to meet you\n",
      "Hello is this the messenger bot?\n",
      "Hello is this the bot?\n",
      "Hello, \n",
      "Good, and you?\n",
      "Fine, you?\n",
      "Great\n",
      "splendid\n",
      "wonderful\n",
      "super\n",
      "Could be better\n",
      "Okay\n",
      "Very well, thanks\n",
      "Fine\n",
      "I'm doing well, thank you\n",
      "Terrible\n",
      "Bad\n",
      "pretty sad today\n",
      "shitty\n",
      "What are your hours?\n",
      "What hours are you open?\n",
      "When are you open?\n",
      "I'd like to make a reservation\n",
      "Do you have availability for tonight?\n",
      "Can I book a table for ?\n",
      "Do you have any specials today?\n",
      "Any deals?\n",
      "Which specials do you have?\n",
      "Any discounts?\n",
      "Any coupons?\n",
      "Do you take credit cards?\n",
      "Do you accept Mastercard?\n",
      "Are you cash only?\n"
     ]
    }
   ],
   "source": [
    "for itera in intents['data']:\n",
    "    print(itera['Context'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get all words, classes, documents form json file \n",
    "words = []\n",
    "classes = []\n",
    "patterns = []\n",
    "ignore_words = ['?']\n",
    "\n",
    "for intent in intents['data']:\n",
    "    pattern = intent['Context']\n",
    "    w = nltk.word_tokenize(pattern) # tokenize words\n",
    "    words.extend(w) # add each to our word list\n",
    "    patterns.append((w, intent['Tag']))\n",
    "    if intent['Tag'] not in classes:\n",
    "        classes.append(intent['Tag'])\n",
    "        \n",
    "\n",
    "# stem and lower each word and remove duplicates\n",
    "words = [stemmer.stem(w.lower()) for w in words if w not in ignore_words]\n",
    "words = sorted(list(set(words)))\n",
    "\n",
    "# remove duplicate classes\n",
    "classes = sorted(list(set(classes)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['', 'greeting', 'hours', 'payment', 'reservation', 'specials']"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
